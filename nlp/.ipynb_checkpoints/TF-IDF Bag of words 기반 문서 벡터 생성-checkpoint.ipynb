{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d523d01",
   "metadata": {},
   "source": [
    "이번 실습에서는 scikit-learn의 TfidfVectorizer를 사용하여, TF-IDF 기반 bag of words 문서 벡터를 만들어 보는 실습을 진행하겠습니다. TfidfVectorizer의 사용법은 CountVectorizer의 사용법과 동일합니다.\n",
    "\n",
    "영화 리뷰 데이터인 text.txt에 저장되어 있는 IMDB dataset을 사용하여 각 리뷰별 문서 벡터를 만들어 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d8ee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 차원\n",
      "(454, 12136)\n",
      "\n",
      "첫 번째 문서의 TF-IDF Bag of words\n",
      "  (0, 5679)\t0.058640619958889736\n",
      "  (0, 8003)\t0.10821800789540346\n",
      "  (0, 11827)\t0.03351360629176965\n",
      "  (0, 3976)\t0.10821800789540346\n",
      "  (0, 3885)\t0.056559253324120214\n",
      "  (0, 10825)\t0.040897765011371726\n",
      "  (0, 228)\t0.07670128660443204\n",
      "  (0, 173)\t0.08289290212342751\n",
      "  (0, 6546)\t0.043212451333837304\n",
      "  (0, 3731)\t0.06944792122696908\n",
      "  (0, 11793)\t0.08712444266241767\n",
      "  (0, 12103)\t0.05368632319734369\n",
      "  (0, 7470)\t0.025687260438575044\n",
      "  (0, 9189)\t0.10821800789540346\n",
      "  (0, 4994)\t0.04450120519256354\n",
      "  (0, 5326)\t0.05241495461089306\n",
      "  (0, 5538)\t0.09654704887371249\n",
      "  (0, 6240)\t0.05908965016142883\n",
      "  (0, 1896)\t0.06002531501567428\n",
      "  (0, 8681)\t0.10139093452026096\n",
      "  (0, 5344)\t0.08289290212342751\n",
      "  (0, 3162)\t0.05211156559734475\n",
      "  (0, 1438)\t0.09278983927035103\n",
      "  (0, 11136)\t0.07804901647687901\n",
      "  (0, 8858)\t0.09654704887371249\n",
      "  :\t:\n",
      "  (0, 8333)\t0.09654704887371249\n",
      "  (0, 10655)\t0.10821800789540346\n",
      "  (0, 5394)\t0.036855273761029705\n",
      "  (0, 12074)\t0.045486142952180335\n",
      "  (0, 7080)\t0.06950749415600704\n",
      "  (0, 10653)\t0.43287203158161386\n",
      "  (0, 10410)\t0.04631780012339499\n",
      "  (0, 6199)\t0.045486142952180335\n",
      "  (0, 9332)\t0.14858361374703516\n",
      "  (0, 22)\t0.030847058442278544\n",
      "  (0, 8343)\t0.09654704887371249\n",
      "  (0, 7576)\t0.03767413181742104\n",
      "  (0, 9948)\t0.03226580332806431\n",
      "  (0, 632)\t0.04595176416002607\n",
      "  (0, 10915)\t0.03552172020508319\n",
      "  (0, 9232)\t0.05368632319734369\n",
      "  (0, 10769)\t0.1528768111964441\n",
      "  (0, 683)\t0.05694325708073058\n",
      "  (0, 8584)\t0.08971997549857\n",
      "  (0, 5685)\t0.038437344953303164\n",
      "  (0, 2038)\t0.05617216421425451\n",
      "  (0, 1605)\t0.08712444266241767\n",
      "  (0, 5672)\t0.07371054752205941\n",
      "  (0, 5036)\t0.2575794789063761\n",
      "  (0, 1356)\t0.43287203158161386\n",
      "\n",
      "TF-IDF 기반 Bag of N-grams 문서 벡터의 차원\n",
      "(454, 74358)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "regex = re.compile('[^a-z ]')\n",
    "\n",
    "# 리뷰 데이터\n",
    "with open(\"text.txt\", 'r', encoding='utf8') as f:\n",
    "    \n",
    "    documents = []\n",
    "    for line in f:\n",
    "        lowered_sent = line.rstrip().lower()\n",
    "        filtered_sent = regex.sub('', lowered_sent)\n",
    "        documents.append(filtered_sent)\n",
    "\n",
    "# TfidfVectorizer() 객체를 이용해 TF-IDF Bag of words 문서 벡터를 생성\n",
    "tfv = TfidfVectorizer()\n",
    "X = tfv.fit_transform(documents)\n",
    "\n",
    "print(f'X의 차원\\n{X.shape}\\n')\n",
    "\n",
    "# 첫 번째 문서의 TF-IDF Bag of words를 vec1 변수에 저장하세요.\n",
    "vec1 = None\n",
    "# 첫 번째 문서의 TF-IDF Bag of words를 확인합니다.\n",
    "print(f'첫 번째 문서의 TF-IDF Bag of words\\n{X[0]}\\n')\n",
    "\n",
    "'''\n",
    "TF-IDF 기반 Bag of N-grams 문서 벡터 생성\n",
    "ngram_range=(1, 2)는 데이터 내 unigram과 bigram을 사용하여 문서 벡터를 생성한다는 의미를 갖고 있습니다.\n",
    "'''\n",
    "tfvn = TfidfVectorizer(ngram_range=(1, 2))\n",
    "unibigram_X = tfvn.fit_transform(documents)\n",
    "\n",
    "\n",
    "print(f'TF-IDF 기반 Bag of N-grams 문서 벡터의 차원\\n{unibigram_X.shape}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
