{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a65ace8",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48097ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "'''\n",
    "1. 선형 회귀 모델의 클래스를 구현합니다.\n",
    "\n",
    "   Step01. 가중치 초기값을 1.5의 값을 가진 변수 텐서로 설정하세요.\n",
    "   \n",
    "   Step02. Bias 초기값을 1.5의 값을 가진 변수 텐서로 설정하세요.\n",
    "   \n",
    "   Step03. W, X, b를 사용해 선형 모델을 구현하세요.\n",
    "'''\n",
    "\n",
    "class LinearModel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.W = tf.Variable(1.5)\n",
    "        \n",
    "        self.b = tf.Variable(1.5)\n",
    "        \n",
    "    def __call__(self, X, Y):\n",
    "        \n",
    "        return tf.add(tf.multiply(X, self.W), self.b)\n",
    "\n",
    "'''\n",
    "2. MSE 값을 계산해 반환하는 손실 함수를 완성합니다. \n",
    "정답과 예측의 오차의 제곱\n",
    "'''\n",
    "\n",
    "def loss(y, pred):\n",
    "    \n",
    "    return tf.reduce_mean(tf.square(y - pred))\n",
    "\n",
    "'''\n",
    "3. gradient descent 방식으로 학습하는 train 함수입니다.\n",
    "   코드를 보면서 어떤 방식으로 W(가중치)와 b(Bias)이\n",
    "   업데이트 되는지 확인해 보세요.\n",
    "   tf.GradientTape안에 연산을 넣어주면 연산에 대한 기록들이 저장됨 나중에 역전파를 수행할 때 사용\n",
    "'''\n",
    "\n",
    "def train(linear_model, x, y):\n",
    "    \n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = loss(y, linear_model(x, y))\n",
    "    \n",
    "    # learning_rate 값 선언\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # gradient 값 역순으로 계산\n",
    "    delta_W, delta_b = t.gradient(current_loss, [linear_model.W, linear_model.b])\n",
    "    \n",
    "    # learning rate와 계산한 gradient 값을 이용하여 업데이트할 파라미터 변화 값 계산 \n",
    "    W_update = (learning_rate * delta_W)\n",
    "    b_update = (learning_rate * delta_b)\n",
    "    \n",
    "    return W_update,b_update\n",
    " \n",
    "def main():\n",
    "    \n",
    "    # 데이터 생성\n",
    "    x_data = np.linspace(0, 10, 50)\n",
    "    y_data = 4 * x_data + np.random.randn(*x_data.shape)*4 + 3\n",
    "    \n",
    "    # 데이터 출력\n",
    "    plt.scatter(x_data,y_data)\n",
    "    plt.savefig('data.png')\n",
    "    elice_utils.send_image('data.png')\n",
    "    \n",
    "    # 선형 함수 적용\n",
    "    linear_model = LinearModel()\n",
    "    \n",
    "    # epochs 값 선언\n",
    "    epochs = 100\n",
    "    \n",
    "    # epoch 값만큼 모델 학습\n",
    "    for epoch_count in range(epochs):\n",
    "        \n",
    "        # 선형 모델의 예측 값 저장\n",
    "        y_pred_data=linear_model(x_data, y_data)\n",
    "        \n",
    "        # 예측 값과 실제 데이터 값과의 loss 함수 값 저장\n",
    "        real_loss = loss(y_data, linear_model(x_data, y_data))\n",
    "        \n",
    "        # 현재의 선형 모델을 사용하여  loss 값을 줄이는 새로운 파라미터로 갱신할 파라미터 변화 값을 계산\n",
    "        update_W, update_b = train(linear_model, x_data, y_data)\n",
    "        \n",
    "        # 선형 모델의 가중치와 Bias를 업데이트합니다. \n",
    "        linear_model.W.assign_sub(update_W)\n",
    "        linear_model.b.assign_sub(update_b)\n",
    "        \n",
    "        # 20번 마다 출력 (조건문 변경 가능)\n",
    "        if (epoch_count%20==0):\n",
    "            print(f\"Epoch count {epoch_count}: Loss value: {real_loss.numpy()}\")\n",
    "            print('W: {}, b: {}'.format(linear_model.W.numpy(), linear_model.b.numpy()))\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            ax1 = fig.add_subplot(111)\n",
    "            ax1.scatter(x_data,y_data)\n",
    "            ax1.plot(x_data,y_pred_data, color='red')\n",
    "            plt.savefig('prediction.png')\n",
    "            elice_utils.send_image('prediction.png')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
