{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24917eee",
   "metadata": {},
   "source": [
    "### 텐서플로우(TensorFlow) 버전 비교하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1206e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tf.enable_eager_execution must be called at program startup.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult_tf2:\u001b[39m\u001b[38;5;124m'\u001b[39m, tf_2)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 56\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [3], line 50\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m---> 50\u001b[0m     tf_2, tf_1 \u001b[38;5;241m=\u001b[39m \u001b[43mtf2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m2\u001b[39m], tf1()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult_tf1:\u001b[39m\u001b[38;5;124m'\u001b[39m, tf_1)\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult_tf2:\u001b[39m\u001b[38;5;124m'\u001b[39m, tf_2)\n",
      "Cell \u001b[1;32mIn [3], line 37\u001b[0m, in \u001b[0;36mtf2\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtf2\u001b[39m():\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_v2_behavior\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# 상수\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     a \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:60\u001b[0m, in \u001b[0;36menable_v2_behavior\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# TF2 behavior is enabled if either 1) enable_v2_behavior() is called or\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# 2) the TF2_BEHAVIOR=1 environment variable is set.  In the latter case,\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# the modules below independently check if tf2.enabled().\u001b[39;00m\n\u001b[0;32m     59\u001b[0m tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 60\u001b[0m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_eager_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m tensor_shape\u001b[38;5;241m.\u001b[39menable_v2_tensorshape()  \u001b[38;5;66;03m# Also switched by tf2\u001b[39;00m\n\u001b[0;32m     62\u001b[0m variable_scope\u001b[38;5;241m.\u001b[39menable_resource_variables()\n",
      "File \u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6149\u001b[0m, in \u001b[0;36menable_eager_execution\u001b[1;34m(config, device_policy, execution_mode)\u001b[0m\n\u001b[0;32m   6147\u001b[0m logging\u001b[38;5;241m.\u001b[39mvlog(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnabling eager execution\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mdefault_execution_mode \u001b[38;5;241m!=\u001b[39m context\u001b[38;5;241m.\u001b[39mEAGER_MODE:\n\u001b[1;32m-> 6149\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menable_eager_execution_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6150\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6151\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdevice_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6152\u001b[0m \u001b[43m      \u001b[49m\u001b[43mexecution_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6153\u001b[0m \u001b[43m      \u001b[49m\u001b[43mserver_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6217\u001b[0m, in \u001b[0;36menable_eager_execution_internal\u001b[1;34m(config, device_policy, execution_mode, server_def)\u001b[0m\n\u001b[0;32m   6214\u001b[0m   graph_mode_has_been_used \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   6215\u001b[0m       _default_graph_stack\u001b[38;5;241m.\u001b[39m_global_default_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   6216\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m graph_mode_has_been_used:\n\u001b[1;32m-> 6217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   6218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.enable_eager_execution must be called at program startup.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6219\u001b[0m context\u001b[38;5;241m.\u001b[39mdefault_execution_mode \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mEAGER_MODE\n\u001b[0;32m   6220\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: tf.enable_eager_execution must be called at program startup."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import logging, os\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "\n",
    "\"\"\"\"\"\n",
    "텐서플로우 1.x 버전\n",
    "\"\"\"\"\"\n",
    "\n",
    "def tf1():\n",
    "    \n",
    "    import tensorflow.compat.v1 as tf\n",
    "    tf.disable_v2_behavior()\n",
    "    \n",
    "    # 상수\n",
    "    a = tf.constant(5)\n",
    "    b = tf.constant(3)\n",
    "    \n",
    "    # 계산 정의\n",
    "    add_op = a + b\n",
    "    \n",
    "    # 세션 시작\n",
    "    sess = tf.Session()\n",
    "    result_tf1 = sess.run(add_op)\n",
    "    \n",
    "    return a, b, result_tf1\n",
    "\n",
    "\"\"\"\"\"\n",
    "텐서플로우 2.0 버전\n",
    "\"\"\"\"\"\n",
    "\n",
    "def tf2():\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    tf.compat.v1.enable_v2_behavior()\n",
    "    \n",
    "    # 상수\n",
    "    a = tf.constant(5)\n",
    "    b = tf.constant(3)\n",
    "    \n",
    "    # 즉시 실행 연산\n",
    "    result_tf2 = tf.add(a, b)\n",
    "    \n",
    "    return a, b, result_tf2.numpy()\n",
    "\n",
    "def main():\n",
    "    \n",
    "    tf_2, tf_1 = tf2()[2], tf1()[2]\n",
    "    '''\n",
    "    result_tf1: 8\n",
    "result_tf2: 8\n",
    "    '''\n",
    "    print('result_tf1:', tf_1)\n",
    "    print('result_tf2:', tf_2)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc95b99",
   "metadata": {},
   "source": [
    "### Tensor Data 생성\n",
    "- 텐서플로우는 상수, 시퀀스, 난수, 변수 등을 텐서(Tensor)형으로 생성하는 연산을 제공합니다. 이러한 연산은 기존 Numpy와 유사하게 사용할 수 있습니다.\n",
    "- 또한, 텐서플로우에는 다양한 자료형을 사용할 수 있습니다. 이를 이용하면 어떤 데이터든지 구조화된 형식으로 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f28654",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;28mprint\u001b[39m(key, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m :\u001b[39m\u001b[38;5;124m'\u001b[39m, value\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 91\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [6], line 78\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m variable_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar_tensor\u001b[39m\u001b[38;5;124m'\u001b[39m:var_tensor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m:W, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m:b}\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m constant_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(key, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m :\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m())\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m sequence_dict\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:446\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    438\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    439\u001b[0m   \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    441\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;124m    from tensorflow.python.ops.numpy_ops import np_config\u001b[39m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;124m    np_config.enable_numpy_behavior()\u001b[39m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m--> 446\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "'''\n",
    "1. 상수 텐서를 생성하는 constant_tensors 함수를 완성하세요.\n",
    "\n",
    "   Step01. 5의 값을 가지는 (1,1) shape의 8-bit integer 텐서를 만드세요.\n",
    "   \n",
    "   Step02. 모든 원소의 값이 0인 (3,5) shape의 16-bit integer 텐서를 만드세요.\n",
    "   \n",
    "   Step03. 모든 원소의 값이 1인 (4,3) shape의 8-bit integer 텐서를 만드세요.\n",
    "'''\n",
    "\n",
    "def constant_tensors():\n",
    "    \n",
    "    t1 = tf.constant(5, shape=(1, 1), dtype=tf.int8)\n",
    "    \n",
    "    t2 = tf.zeros(shape=(3, 5), dtype=tf.int16)\n",
    "    \n",
    "    t3 = tf.ones(shape=(4, 3), dtype=tf.int8)\n",
    "    \n",
    "    return t1, t2, t3\n",
    "\n",
    "'''\n",
    "2. 시퀀스 텐서를 생성하는 sequence_tensors 함수를 완성하세요. \n",
    "\n",
    "   Step01. 1.5에서 10.5까지 증가하는 3개의 텐서를 만드세요.\n",
    "   \n",
    "   Step02. 2.5에서 20.5까지 증가하는 5개의 텐서를 만드세요. \n",
    "'''\n",
    "\n",
    "def sequence_tensors():\n",
    "    \n",
    "    seq_t1 = tf.range(1.5, 11, 4.5)\n",
    "    \n",
    "    seq_t2 = tf.range(2.5, 21, 4.5)\n",
    "    \n",
    "    return seq_t1, seq_t2\n",
    "\n",
    "'''\n",
    "3. 변수를 생성하는 variable_tensor 함수를 완성하세요.\n",
    "\n",
    "   Step01. 값이 100인 변수 텐서를 만드세요.\n",
    "   \n",
    "   Step02. 모든 원소의 값이 1인 (2,2) shape의 변수 텐서를 만드세요.\n",
    "           이름도 'W'로 지정합니다.\n",
    "   \n",
    "   Step03. 모든 원소의 값이 0인 (2,) shape의 변수 텐서를 만드세요.\n",
    "           이름도 'b'로 지정합니다.\n",
    "'''\n",
    "\n",
    "def variable_tensor():\n",
    "    \n",
    "    var_tensor = tf.Variable(initial_value=100)\n",
    "    \n",
    "    W = tf.Variable(tf.ones(shape=(2, 2)), name='W')\n",
    "    \n",
    "    b = tf.Variable(tf.zeros(shape=(2,)), name='b')\n",
    "    \n",
    "    return var_tensor, W, b\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    출력\n",
    "    t1  : [[5]]\n",
    "t2  : [[0 0 0 0 0]\n",
    " [0 0 0 0 0]\n",
    " [0 0 0 0 0]]\n",
    "t3  : [[1 1 1]\n",
    " [1 1 1]\n",
    " [1 1 1]\n",
    " [1 1 1]]\n",
    "\n",
    "seq_t1  : [ 1.5  6.  10.5]\n",
    "seq_t2  : [ 2.5  7.  11.5 16.  20.5]\n",
    "\n",
    "var_tensor  : 100\n",
    "W  : [[1. 1.]\n",
    " [1. 1.]]\n",
    "b  : [0. 0.]\n",
    "    '''\n",
    "    \n",
    "    t1, t2, t3 = constant_tensors()\n",
    "    \n",
    "    seq_t1,seq_t2 = sequence_tensors()\n",
    "    \n",
    "    var_tensor, W, b = variable_tensor()\n",
    "    \n",
    "    constant_dict = {'t1':t1, 't2':t2, 't3':t3}\n",
    "    \n",
    "    sequence_dict = {'seq_t1':seq_t1, 'seq_t2':seq_t2}\n",
    "    \n",
    "    variable_dict = {'var_tensor':var_tensor, 'W':W, 'b':b}\n",
    "    \n",
    "    for key, value in constant_dict.items():\n",
    "        print(key, ' :', value.numpy())\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    for key, value in sequence_dict.items():\n",
    "        print(key, ' :', value.numpy())\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    for key, value in variable_dict.items():\n",
    "        print(key, ' :', value.numpy())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a52d14",
   "metadata": {},
   "source": [
    "### Tensor 연산\n",
    "이항 연산자\n",
    "\n",
    "- tf.add(x, y) : x 텐서와 y 텐서를 더합니다.\n",
    "- tf.subtract(x, y) : x 텐서에서 y 텐서를 뺍니다.\n",
    "- tf.multiply(x, y) : x 텐서와 y 텐서를 곱합니다.\n",
    "- tf.truediv(x, y) : x 텐서를 y 텐서로 나눕니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d8d45d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m add, sub, mul, div\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [7], line 30\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m tensor_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m:add, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub\u001b[39m\u001b[38;5;124m'\u001b[39m:sub, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmul\u001b[39m\u001b[38;5;124m'\u001b[39m:mul, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m:div}\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m tensor_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(key, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m :\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m add, sub, mul, div\n",
      "File \u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:446\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    438\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    439\u001b[0m   \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    441\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;124m    from tensorflow.python.ops.numpy_ops import np_config\u001b[39m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;124m    np_config.enable_numpy_behavior()\u001b[39m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m--> 446\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "'''\n",
    "1. 이항 연산자를 사용해 사칙 연산을 수행하여 각 변수에 저장하세요.\n",
    "\n",
    "   Step01. 텐서 'a'와 'b'를 더해 'add'에 저장하세요.\n",
    "   \n",
    "   Step02. 텐서 'a'에서 'b'를 빼 'sub'에 저장하세요.\n",
    "   \n",
    "   Step03. 텐서 'a'와 'b'를 곱해 'mul'에 저장하세요.\n",
    "   \n",
    "   Step04. 텐서 'a'에서 'b'를 나눠 'div'에 저장하세요.\n",
    "'''\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    출력\n",
    "    add  : 13 \n",
    "\n",
    "sub  : 7 \n",
    "\n",
    "mul  : 30 \n",
    "\n",
    "div  : 3.3333333333333335 \n",
    "    '''\n",
    "    a = tf.constant(10, dtype = tf.int32)\n",
    "    b = tf.constant(3, dtype = tf.int32)\n",
    "    \n",
    "    add = tf.add(a, b)\n",
    "    sub = tf.subtract(a, b)\n",
    "    mul = tf.multiply(a, b)\n",
    "    div = tf.truediv(a, b)\n",
    "    \n",
    "    tensor_dict = {'add':add, 'sub':sub, 'mul':mul, 'div':div}\n",
    "    \n",
    "    for key, value in tensor_dict.items():\n",
    "        print(key, ' :', value.numpy(), '\\n')\n",
    "    \n",
    "    return add, sub, mul, div\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec48872",
   "metadata": {},
   "source": [
    "### Tensorflow를 활용한 선형회귀\n",
    "- 선형 회귀란 데이터를 가장 잘 설명하는 선을 찾아 입력값에 따른 미래 결괏값을 예측하는 알고리즘\n",
    "- 텐서플로우를 활용해 손실 함수와 선형 회귀 직선을 직접 구현한 후, 모델의 학습 과정을 통해 가중치(Weight)와 Bias가 어떻게 변화되는지 알아보자\n",
    "- 손실 함수로 MSE를 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbb0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "'''\n",
    "1. 선형 회귀 모델의 클래스를 구현합니다.\n",
    "\n",
    "   Step01. 가중치 초기값을 1.5의 값을 가진 변수 텐서로 설정하세요.\n",
    "   \n",
    "   Step02. Bias 초기값을 1.5의 값을 가진 변수 텐서로 설정하세요.\n",
    "   \n",
    "   Step03. W, X, b를 사용해 선형 모델을 구현하세요.\n",
    "'''\n",
    "\n",
    "class LinearModel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.W = None\n",
    "        \n",
    "        self.b = None\n",
    "        \n",
    "    def __call__(self, X, Y):\n",
    "        \n",
    "        return None\n",
    "\n",
    "'''\n",
    "2. MSE 값을 계산해 반환하는 손실 함수를 완성합니다. \n",
    "'''\n",
    "\n",
    "def loss(y, pred):\n",
    "    \n",
    "    return None\n",
    "\n",
    "'''\n",
    "3. gradient descent 방식으로 학습하는 train 함수입니다.\n",
    "   코드를 보면서 어떤 방식으로 W(가중치)와 b(Bias)이\n",
    "   업데이트 되는지 확인해 보세요.\n",
    "'''\n",
    "\n",
    "def train(linear_model, x, y):\n",
    "    \n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = loss(y, linear_model(x, y))\n",
    "    \n",
    "    # learning_rate 값 선언\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # gradient 값 계산\n",
    "    delta_W, delta_b = t.gradient(current_loss, [linear_model.W, linear_model.b])\n",
    "    \n",
    "    # learning rate와 계산한 gradient 값을 이용하여 업데이트할 파라미터 변화 값 계산 \n",
    "    W_update = (learning_rate * delta_W)\n",
    "    b_update = (learning_rate * delta_b)\n",
    "    \n",
    "    return W_update,b_update\n",
    " \n",
    "def main():\n",
    "    \n",
    "    # 데이터 생성\n",
    "    x_data = np.linspace(0, 10, 50)\n",
    "    y_data = 4 * x_data + np.random.randn(*x_data.shape)*4 + 3\n",
    "    \n",
    "    # 데이터 출력\n",
    "    plt.scatter(x_data,y_data)\n",
    "    plt.savefig('data.png')\n",
    "    elice_utils.send_image('data.png')\n",
    "    \n",
    "    # 선형 함수 적용\n",
    "    linear_model = LinearModel()\n",
    "    \n",
    "    # epochs 값 선언\n",
    "    epochs = 100\n",
    "    \n",
    "    # epoch 값만큼 모델 학습\n",
    "    for epoch_count in range(epochs):\n",
    "        \n",
    "        # 선형 모델의 예측 값 저장\n",
    "        y_pred_data=linear_model(x_data, y_data)\n",
    "        \n",
    "        # 예측 값과 실제 데이터 값과의 loss 함수 값 저장\n",
    "        real_loss = loss(y_data, linear_model(x_data, y_data))\n",
    "        \n",
    "        # 현재의 선형 모델을 사용하여  loss 값을 줄이는 새로운 파라미터로 갱신할 파라미터 변화 값을 계산\n",
    "        update_W, update_b = train(linear_model, x_data, y_data)\n",
    "        \n",
    "        # 선형 모델의 가중치와 Bias를 업데이트합니다. \n",
    "        linear_model.W.assign_sub(update_W)\n",
    "        linear_model.b.assign_sub(update_b)\n",
    "        \n",
    "        # 20번 마다 출력 (조건문 변경 가능)\n",
    "        if (epoch_count%20==0):\n",
    "            print(f\"Epoch count {epoch_count}: Loss value: {real_loss.numpy()}\")\n",
    "            print('W: {}, b: {}'.format(linear_model.W.numpy(), linear_model.b.numpy()))\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            ax1 = fig.add_subplot(111)\n",
    "            ax1.scatter(x_data,y_data)\n",
    "            ax1.plot(x_data,y_pred_data, color='red')\n",
    "            plt.savefig('prediction.png')\n",
    "            elice_utils.send_image('prediction.png')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
