{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f5b6e43",
   "metadata": {},
   "source": [
    "## RSS(Residual Sum of Square) - 단순 오차\n",
    "1. 실제값과 예측값의 단순 오차 제곱의 합\n",
    "2. 값이 작을 수록 모델의 성능은 높음\n",
    "3. 오차를 그래도 사용하기 때문에 입력값의 크기에 의존적\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5032f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 데이터 X와 y를 생성하고, 학습용 데이터와 테스트용 데이터로 분리하여 반환하는 함수입니다.\n",
    "def load_data():\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    X = 5*np.random.rand(100,1)\n",
    "    y = 3*X + 5*np.random.rand(100,1)\n",
    "     \n",
    "    train_X, test_X, train_y, test_y = train_test_split(X,y,test_size=0.3, random_state=0)\n",
    "    \n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "# 회귀 모델을 불러오고, 불러온 모델을 학습용 데이터에 맞춰 학습시켜 반환하는 함수입니다.\n",
    "def Linear_Regression(train_X, train_y):\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    lr.fit(train_X,train_y)\n",
    "    \n",
    "    return lr\n",
    "    \n",
    "\"\"\"\n",
    "1. RSS(Residual Sum of Squares)를 계산하여\n",
    "   반환하는 함수를 완성합니다.\n",
    "\"\"\"\n",
    "def return_RSS(test_y, predicted):\n",
    "    \n",
    "    RSS = 0\n",
    "    for i in range(len(test_y)):\n",
    "        RSS += (test_y[i] - predicted[i])**2\n",
    "    \n",
    "    return RSS\n",
    "    \n",
    "    \n",
    "# 그래프로 시각화합니다.\n",
    "def plotting_graph(test_X, test_y, predicted):\n",
    "    plt.scatter(test_X,test_y)\n",
    "    plt.plot(test_X, predicted, color='r')\n",
    "    \n",
    "    plt.savefig(\"result.png\")\n",
    "    elice_utils.send_image(\"result.png\")\n",
    "\n",
    "\"\"\"\n",
    "3. 정의한 함수들을 이용하여 main() 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 생성한 데이터를 \n",
    "           학습용 데이터와 테스트 데이터로\n",
    "           분리하여 반환하는 함수를 호출합니다.\n",
    "           \n",
    "   Step02. 학습용 데이터를 바탕으로 학습한 선형 회귀 \n",
    "           모델을 반환하는 함수를 호출합니다.\n",
    "          \n",
    "   Step03. 학습된 모델을 바탕으로 계산된 \n",
    "           테스트 데이터의 예측값을 predicted에\n",
    "           저장합니다.\n",
    "           \n",
    "   Step04. 회귀 알고리즘을 평가하기 위한 RSS 값을 RSS에\n",
    "           저장합니다.\n",
    "\"\"\"\n",
    "def main():\n",
    "    \n",
    "    train_X, train_y, test_X, test_y = load_data()\n",
    "     \n",
    "    lr = Linear_Regression(train_X, train_y)\n",
    "    \n",
    "    predicted = lr.predict(test_X)\n",
    "    \n",
    "    RSS = return_RSS(test_y, predicted)\n",
    "    print(\"> RSS :\",RSS)\n",
    "    \n",
    "    plotting_graph(test_X, test_y, predicted)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838453d5",
   "metadata": {},
   "source": [
    "## MSE, MAE - 절대적 크기에 의존한 지표\n",
    "- MSE(Mean Squared Error)\n",
    "    - 평균 제곱 오차, RSS에서 데이터 수만큼 나눈 값\n",
    "    - 작을 수록 모델의 성능이 높다고 평가할 수 있음\n",
    "    - 이상치(Outlier)에 민감\n",
    "- MAE(Mean Absolute Error)\n",
    "    - 평균 절대값 오차, 실제값과 예측값의 오차의 절대값의 평균\n",
    "    - 작을 수록 모델의 성능이 높다고 평가할 수 있음\n",
    "    - 변동성이 큰 지표와 작은 지표를 같이 예측할 시 유용\n",
    "- 평균을 그대로 사용하기 때문에 입력값의 크기에 의존적\n",
    "\n",
    "MSE, MAE 평가 지표를 계산하기 위한 사이킷런 함수/라이브러리\n",
    "\n",
    "- from sklearn.metrics import mean_absolute_error : MAE 평가 지표 계산 기능 불러오기\n",
    "- mean_absolute_error(y_true, y_pred): MAE 값 계산하기\n",
    "- from sklearn.metrics import mean_squared_error: MSE 평가 지표 계산 기능 불러오기\n",
    "- mean_squared_error(y_true, y_pred): MSE 값 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f495b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 데이터 X와 y를 생성하고, 학습용 데이터와 테스트용 데이터로 분리하여 반환하는 함수입니다.\n",
    "def load_data():\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    X = 5*np.random.rand(100,1)\n",
    "    y = 3*X + 5*np.random.rand(100,1)\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = train_test_split(X,y,test_size=0.3, random_state=0)\n",
    "    \n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "# 회귀 모델을 불러오고, 불러온 모델을 학습용 데이터에 맞춰 학습시켜 반환하는 함수입니다.\n",
    "def Linear_Regression(train_X, train_y):\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    lr.fit(train_X,train_y)\n",
    "    \n",
    "    return lr\n",
    "    \n",
    "# 그래프로 시각화합니다.\n",
    "def plotting_graph(test_X, test_y, predicted):\n",
    "    plt.scatter(test_X,test_y)\n",
    "    plt.plot(test_X, predicted, color='r')\n",
    "    \n",
    "    plt.savefig(\"result.png\")\n",
    "    elice_utils.send_image(\"result.png\")\n",
    "\n",
    "\"\"\"\n",
    "1. 정의한 함수들을 이용하여 main() 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 생성한 데이터를 \n",
    "           학습용 데이터와 테스트 데이터로 \n",
    "           분리하여 반환하는 함수를 호출합니다.\n",
    "           \n",
    "   Step02. 학습용 데이터를 바탕으로 학습한 선형 회귀\n",
    "           모델을 반환하는 함수를 호출합니다.\n",
    "          \n",
    "   Step03. 학습된 모델을 바탕으로 계산된 \n",
    "           테스트 데이터의 예측값을 predicted에\n",
    "           저장합니다.\n",
    "           \n",
    "   Step04. 회귀 알고리즘을 평가하기 위한 MSE, MAE 값을 \n",
    "           각각 MSE,MAE 에 저장합니다.\n",
    "\"\"\"\n",
    "def main():\n",
    "    \n",
    "    train_X, train_y, test_X, test_y = load_data()\n",
    "    \n",
    "    lr = Linear_Regression(train_X, train_y)\n",
    "    \n",
    "    predicted = lr.predict(test_X)\n",
    "    \n",
    "    MAE = mean_absolute_error(test_y, predicted)\n",
    "    MSE = mean_squared_error(test_y, predicted)\n",
    "\n",
    "    \n",
    "    print(\"> MSE :\",MSE)\n",
    "    print(\"> MAE :\",MAE)\n",
    "    \n",
    "    plotting_graph(test_X, test_y, predicted)\n",
    "    \n",
    "    return MSE, MAE\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25eb9a",
   "metadata": {},
   "source": [
    "## R_square (결정계수)\n",
    "- 회귀 모델의 설명력을 표현하는 지표\n",
    "- 1에 가까울 수록 높은 성능의 모델이라고 평가할 수 있음\n",
    "- 백분율로 표현하기 때문에 크기에 의존적이지 않음\n",
    "- 실제값이 1보다 작을 경우, 무한대에 가까운 값 도출, 실제값이 0일 경우 계산 불가\n",
    "\n",
    "RSS, MSE, MAE 지표들은 “오차” 에 기반한 지표들이기 때문에 해당 값들이 작을수록 더 높은 성능의 모델을 의미하지만, $R^2$지표의 경우 데이터에 대한 모델의 설명력을 의미하기 때문에 1에 가까울수록 즉, 더 클수록 높은 성능의 모델임을 의미한다.\n",
    "\n",
    "$R^2$ 평가 지표를 계산하기 위한 사이킷런 함수/라이브러리\n",
    "\n",
    "- from sklearn.metrics import r2_score :$R^2$평가 지표 계산 기능 불러오기\n",
    "- r2_score(y_true, y_pred) : $R^2$값 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444582ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 데이터 X와 y를 생성하고, 학습용 데이터와 테스트용 데이터로 분리하여 반환하는 함수입니다.\n",
    "def load_data():\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    X = 5*np.random.rand(100,1)\n",
    "    y = 3*X + 5*np.random.rand(100,1)\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = train_test_split(X,y,test_size=0.3, random_state=0)\n",
    "    \n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "# 회귀 모델을 불러오고, 불러온 모델을 학습용 데이터에 맞춰 학습시켜 반환하는 함수입니다.\n",
    "def Linear_Regression(train_X, train_y):\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    lr.fit(train_X,train_y)\n",
    "    \n",
    "    return lr\n",
    "    \n",
    "# 그래프로 시각화합니다.\n",
    "def plotting_graph(test_X, test_y, predicted):\n",
    "    plt.scatter(test_X,test_y)\n",
    "    plt.plot(test_X, predicted, color='r')\n",
    "    \n",
    "    plt.savefig(\"result.png\")\n",
    "    elice_utils.send_image(\"result.png\")\n",
    "\n",
    "\"\"\"\n",
    "1. 정의한 함수들을 이용하여 main() 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 생성한 데이터를 \n",
    "           학습용 데이터와 테스트 데이터로 \n",
    "           분리하여 반환하는 함수를 호출합니다.\n",
    "           \n",
    "   Step02. 학습용 데이터를 바탕으로 학습한 선형 회귀\n",
    "           모델을 반환하는 함수를 호출합니다.\n",
    "          \n",
    "   Step03. 학습된 모델을 바탕으로 계산된\n",
    "           테스트 데이터의 예측값을 predicted에\n",
    "           저장합니다.\n",
    "           \n",
    "   Step04. 회귀 알고리즘을 평가하기 위한 r2_score값을 \n",
    "           R_squared에 저장합니다.\n",
    "\"\"\"\n",
    "def main():\n",
    "    \n",
    "    train_X, train_y, test_X, test_y = load_data()\n",
    "    \n",
    "    lr = Linear_Regression(train_X, train_y)\n",
    "    \n",
    "    predicted = lr.predict(test_X)\n",
    "    \n",
    "    R_squared  = r2_score(test_y, predicted)\n",
    "    \n",
    "    print(\"> R_squared :\",R_squared)\n",
    "    \n",
    "    plotting_graph(test_X, test_y, predicted)\n",
    "    \n",
    "    return R_squared\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
