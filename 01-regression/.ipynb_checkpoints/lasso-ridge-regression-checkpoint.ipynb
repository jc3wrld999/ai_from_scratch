{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a2ab05d",
   "metadata": {},
   "source": [
    "## Lasso회귀(과대적합 방지를 위한 L1정규화)\n",
    "정규화 방법을 적용한 총 3가지(릿지, 라쏘, 엘라스틱 넷) 과적합 방지 모델 중 라쏘 회귀는 회귀학습에 사용되는 Loss Function(비용 함수)에 L1 정규화 항을 추가하고 중요하지 않은 $β0$을 0으로 만들어 모델의 복잡성을 줄일 수 있다.\n",
    "## Rasso 회귀(과대적합 방지를 위한 L2정규화)\n",
    "중요하지 않은 $β0$의 값을 0에 가깝게 만들어 모델의 복잡성을 줄임\n",
    "\n",
    "사이킷런 데이터의 변수 이름을 불러오기 위한 방법\n",
    "- load_boston().feature_names : boston 데이터의 변수 이름을 반환합니다.\n",
    "\n",
    "릿지(Ridge), 라쏘(Lasso) 회귀를 위한 사이킷런 라이브러리/함수\n",
    "- from sklearn.linear_model import Ridge : 사이킷런에 저장된 릿지 회귀를 불러옵니다.\n",
    "- Ridge(alpha): 릿지 회귀를 정의합니다.\n",
    "    - alpha: 기본값은 1입니다.\n",
    "    - alpha값이 클수록 더 강한 정규화를 적용합니다.\n",
    "- from sklearn.linear_model import Lasso : 사이킷런에 저장된 라쏘 회귀를 불러옵니다.\n",
    "- Lasso(alpha): 라쏘 회귀를 정의합니다.\n",
    "    - alpha: 기본값은 1입니다.\n",
    "    - alpha값이 클수록 더 강한 정규화를 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cbe2be3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elice_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01melice_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EliceUtils\n\u001b[0;32m      6\u001b[0m elice_utils \u001b[38;5;241m=\u001b[39m EliceUtils()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ridge\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'elice_utils'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\"\"\"\n",
    "1. 사이킷런에 존재하는 데이터를 불러오고, \n",
    "   불러온 데이터를 학습용 데이터와 테스트용 데이터로 \n",
    "   분리하여 반환하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 존재하는 boston 데이터를 \n",
    "           (X, y)의 형태로 불러옵니다. \n",
    "   \n",
    "   Step02. 데이터의 변수 이름을 feature_names 에\n",
    "           저장합니다.\n",
    "\"\"\"\n",
    "def load_data():\n",
    "    \n",
    "    X, y = load_boston(return_X_y=True)\n",
    "    \n",
    "    feature_names = load_boston().feature_names \n",
    "    \n",
    "    return X,y,feature_names\n",
    "    \n",
    "\"\"\"\n",
    "2. 릿지(Ridge) 회귀를 구현하고, \n",
    "   전체 데이터를 바탕으로 학습시킨 모델을 \n",
    "   반환하는 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 구현되어 있는 \n",
    "           릿지(Ridge) 회귀 모델을 불러옵니다.\n",
    "           \n",
    "           파라미터 alpha를 10으로 설정합니다.\n",
    "   \n",
    "   Step02. 불러온 모델을 전체 데이터에 맞춰\n",
    "           학습시킵니다.\n",
    "\"\"\"\n",
    "def Ridge_regression(X, y):\n",
    "    \n",
    "    ridge_reg = Ridge(10)\n",
    "    \n",
    "    ridge_reg.fit(X, y)\n",
    "    \n",
    "    return ridge_reg\n",
    "\n",
    "\"\"\"\n",
    "2. 라쏘(Lasso) 회귀를 구현하고, \n",
    "   전체 데이터를 바탕으로 학습시킨 모델을 \n",
    "   반환하는 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 구현되어 있는 \n",
    "           라쏘(Lasso) 회귀 모델을 불러옵니다.\n",
    "           \n",
    "           파라미터 alpha를 10으로 설정합니다.\n",
    "   \n",
    "   Step02. 불러온 모델을 전체 데이터에 맞춰\n",
    "           학습시킵니다.\n",
    "\"\"\"\n",
    "def Lasso_regression(X, y):\n",
    "    \n",
    "    lasso_reg = Lasso(10)\n",
    "    \n",
    "    lasso_reg.fit(X, y)\n",
    "    \n",
    "    return lasso_reg\n",
    "    \n",
    "# 각 변수의 beta_i 크기를 시각화하는 함수입니다.\n",
    "def plot_graph(coef, title):\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.ylim(-1,1)\n",
    "    plt.title(title)\n",
    "    coef.plot(kind='bar')\n",
    "\n",
    "    plt.savefig(\"result.png\")\n",
    "    elice_utils.send_image(\"result.png\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    X,y,feature_names = load_data()\n",
    "    \n",
    "    ridge_reg = Ridge_regression(X, y)\n",
    "    lasso_reg = Lasso_regression(X, y)\n",
    "    \n",
    "    ## Ridge 회귀의 beta_i의 크기를 저장합니다.\n",
    "    ridge_coef = pd.Series(ridge_reg.coef_, feature_names).sort_values()\n",
    "    print(\"Ridge 회귀의 beta_i\\n\", ridge_coef)\n",
    "    \n",
    "    ## Lasso 회귀의 beta_i의 크기를 저장합니다.\n",
    "    lasso_coef = pd.Series(lasso_reg.coef_, feature_names).sort_values()\n",
    "    print(\"Lasso 회귀의 beta_i\\n\", lasso_coef)\n",
    "    \n",
    "    plot_graph(ridge_coef, 'Ridge')\n",
    "    plot_graph(lasso_coef, 'Lasso')\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
