{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0541ebe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993466a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import elice_utils\n",
    "eu = elice_utils.EliceUtils()\n",
    "\n",
    "def loss(x, y, beta_0, beta_1):\n",
    "    N = len(x)\n",
    "    loss = 0\n",
    "    '''\n",
    "    이전 실습에서 구현한 loss function을 여기에 붙여넣습니다.\n",
    "    '''\n",
    "    for i in range(N):\n",
    "        loss += (y[i] - (beta_0 * x[i] + beta_1))**2\n",
    "    return loss\n",
    "    \n",
    "X = [8.70153760, 3.90825773, 1.89362433, 3.28730045, 7.39333004, 2.98984649, 2.25757240, 9.84450732, 9.94589513, 5.48321616]\n",
    "Y = [5.64413093, 3.75876583, 3.87233310, 4.40990425, 6.43845020, 4.02827829, 2.26105955, 7.15768995, 6.29097441, 5.19692852]\n",
    "\n",
    "train_X = np.array(X).reshape(-1, 1) # 길이 10인 1차원 리스트 X 를 10×1 형태의 np.array로 변경\n",
    "train_Y = np.array(Y) # 종속변수 Y는 독립변수 X에 대한 값이므로 reshape(-1, 1)을 할 필요가 없다.\n",
    "\n",
    "'''\n",
    "여기에서 모델을 트레이닝합니다.\n",
    "'''\n",
    "lrmodel = LinearRegression()\n",
    "lrmodel.fit(train_X, train_Y)\n",
    "\n",
    "'''\n",
    "loss가 최소가 되는 직선의 기울기와 절편을 계산함\n",
    "'''\n",
    "beta_0 = lrmodel.coef_[0]   # lrmodel로 구한 직선의 기울기\n",
    "beta_1 = lrmodel.intercept_ # lrmodel로 구한 직선의 y절편\n",
    "\n",
    "print(\"beta_0: %f\" % beta_0)\n",
    "print(\"beta_1: %f\" % beta_1)\n",
    "print(\"Loss: %f\" % loss(X, Y, beta_0, beta_1))\n",
    "\n",
    "plt.scatter(X, Y) # (x, y) 점을 그립니다.\n",
    "plt.plot([0, 10], [beta_1, 10 * beta_0 + beta_1], c='r') # y = beta_0 * x + beta_1 에 해당하는 선을 그립니다.\n",
    "\n",
    "plt.xlim(0, 10) # 그래프의 X축을 설정합니다.\n",
    "plt.ylim(0, 10) # 그래프의 Y축을 설정합니다.\n",
    "plt.savefig(\"test.png\") # 저장\n",
    "eu.send_image(\"test.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979fe6a6",
   "metadata": {},
   "source": [
    "### 다중회귀분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d877d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# ./data/Advertising.csv 에 위치한 파일로부터 데이터를 읽어 X와 Y를 만듭니다.\n",
    "import csv\n",
    "csvreader = csv.reader(open(\"data/Advertising.csv\"))\n",
    "\n",
    "\n",
    "# X는 (200, 3) shape을 가진 2차원 np.array로 , TV, Newspaper Column에 해당하는 데이터를 저장합니다. \n",
    "# Y는 (200,) 의 shape을 가진 1차원 np.array로 Sales Column에 해당하는 데이터를 저장합니다.\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "next(csvreader)\n",
    "for line in csvreader :\n",
    "    x_i = [ float(line[1]), float(line[2]), float(line[3]) ] # 'FB', 'TV', 'Newspaper'\n",
    "    y_i = float(line[4]) # Sales\n",
    "    x.append(x_i)\n",
    "    y.append(y_i)\n",
    "\n",
    "X = np.array(x)\n",
    "Y = np.array(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "# Scikit-learn 라이브러리를 이용해 다중 선형 회귀 분석을 진행\n",
    "lrmodel = LinearRegression()\n",
    "lrmodel.fit(X, Y)\n",
    "\n",
    "beta_0 = lrmodel.coef_[0] # 0번째 변수에 대한 계수 (페이스북), 기울기\n",
    "beta_1 = lrmodel.coef_[1] # 1번째 변수에 대한 계수 (TV), 기울기\n",
    "beta_2 = lrmodel.coef_[2] # 2번째 변수에 대한 계수 (신문), 기울기\n",
    "beta_3 = lrmodel.intercept_ # y절편 (기본 판매량)\n",
    "\n",
    "print(\"beta_0: %f\" % beta_0)\n",
    "print(\"beta_1: %f\" % beta_1)\n",
    "print(\"beta_2: %f\" % beta_2)\n",
    "print(\"beta_3: %f\" % beta_3)\n",
    "\n",
    "\n",
    "def expected_sales(fb, tv, newspaper, beta_0, beta_1, beta_2, beta_3):\n",
    "    '''\n",
    "    학습된 모델을 이용해 FB, TV, Newspaper의 값에 따라 예상되는 Sales 값을 expected_sales 에 작성\n",
    "    FB에 fb만큼, TV에 tv만큼, Newspaper에 newspaper 만큼의 광고비를 사용했고,\n",
    "    트레이닝된 모델의 weight 들이 beta_0, beta_1, beta_2, beta_3 일 때\n",
    "    예상되는 Sales 의 양을 출력\n",
    "    '''\n",
    "    sales = beta_0 * fb + beta_1 * tv + beta_2 * newspaper + beta_3\n",
    "    return sales\n",
    "\n",
    "print(\"예상 판매량: %f\" % expected_sales(10, 12, 3, beta_0, beta_1, beta_2, beta_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98017e6",
   "metadata": {},
   "source": [
    "## 숙제 - 다항식 회귀분석\n",
    "\n",
    "#### [⏩ 영상 바로가기](#video-00:30:55-00:35:52)\n",
    "\n",
    "다항식 회귀분석(Polynomial Linear Regression)은 다항식 회귀분석과 원리가 같습니다. \n",
    "다만 데이터에 전처리를 함으로써 새로운 변수 간의 조합을 만들어낸 뒤 회귀분석을 진행하는 것이 차이입니다.\n",
    "\n",
    "다항식 회귀분석을 통해 MSE(Mean Squared Error) 값을 원하는 수준까지 맞춰보겠습니다. \n",
    "\n",
    "### Overfitting\n",
    "\n",
    "데이터는 크게 트레이닝(training)과 테스트(Test) 세트로 나누어집니다. 트레이닝 데이터는 모델을 학습할 때, 테스트 데이터는 학습한 모델을 평가할 때 사용됩니다.\n",
    "\n",
    "모델을 복잡하게 만들면 트레이닝 데이터에서 정확도를 높힐 수 있지만 동일한 모델을 테스트 데이터에 적용하면 과적합(Overfitting) 현상이 일어나게 됩니다.\n",
    "## 숙제 시작하기\n",
    "\n",
    "1. [[실습 4]](https://academy.elice.io/courses/257/lectures/1898/materials/2)와 동일한 방법으로 데이터를 불러오세요.\n",
    "\n",
    "1. 주어진 코드를 살펴보세요. 스켈레톤 코드는 다음 모델을 구현한 것입니다.\n",
    "\n",
    "    $Sales = \\beta_0 X_1^2 + \\beta_1 X_2 + \\beta_2 X_2 X_3 + \\beta_3 X_3 + \\beta_4$\n",
    "\n",
    "1. 주어진 모델에서 변수의 조합을 더하거나 빼면서 MSE의 값을 최대한 낮춰보세요.\n",
    "\n",
    "1. 테스트 데이터에서의 MSE를 1 미만으로 만들어보세요. 모델을 복잡하게 만들 경우 과적합이 일어나는 점을 주의하세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df611f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "csvreader = csv.reader(open(\"data/Advertising.csv\"))\n",
    "\n",
    "next(csvreader)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for line in csvreader :\n",
    "    x_i = [ float(line[1]), float(line[2]), float(line[3]) ]\n",
    "    y_i = float(line[4])\n",
    "    X.append(x_i)\n",
    "\n",
    "\n",
    "\n",
    "    Y.append(y_i)\n",
    "    \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_poly = []\n",
    "for x_i in X:\t    # X_poly 변수를 구성하는 부분으로서, 구성하는 방법은 자유임.\n",
    "    X_poly.append([\n",
    "        x_i[0] ** 3,\n",
    "        x_i[1] ** 3,\n",
    "        x_i[2] ** 3,\n",
    "        x_i[0] ** 2,\n",
    "        x_i[1] ** 2,\n",
    "        x_i[2] ** 2,\n",
    "        x_i[0] * x_i[1],\n",
    "        x_i[1] * x_i[2],\n",
    "        x_i[2] * x_i[0],\n",
    "        x_i[0],\n",
    "        x_i[1],\n",
    "        x_i[2]\n",
    "    ])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_poly, Y, test_size=0.2,random_state=420)\n",
    "\n",
    "lrmodel = LinearRegression()\n",
    "lrmodel.fit(x_train, y_train)\n",
    "\n",
    "predicted_y_train = lrmodel.predict(x_train)\n",
    "mse_train = mean_squared_error(y_train, predicted_y_train)\n",
    "print(\"MSE on train data: {}\".format(mse_train))\n",
    "\n",
    "predicted_y_test = lrmodel.predict(x_test)\n",
    "mse_test = mean_squared_error(y_test, predicted_y_test)\n",
    "print(\"MSE on test data: {}\".format(mse_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
